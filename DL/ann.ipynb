{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤í–‰ë§ˆë‹¤ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ ì¼€ë¼ìŠ¤ì— ëœë¤ ì‹œë“œë¥¼ ì‚¬ìš©í•˜ê³  í…ì„œí”Œë¡œ ì—°ì‚°ì„ ê²°ì •ì ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_input.shape, train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_input.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 10, figsize=(10,10))\n",
    "for i in range(10):\n",
    "    axs[i].imshow(train_input[i], cmap='gray_r')\n",
    "    axs[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([train_target[i] for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.unique(train_target, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = train_input / 255.0\n",
    "train_scaled = train_scaled.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ ì„ íƒ & ë°ì´í„° ì „ì²˜ë¦¬\n",
    "- í›ˆë ¨ ìƒ˜í”Œì´ 60000ê°œë‚˜ ë˜ê¸° ë•Œë¬¸ì— í•œ ë²ˆì— ë‹¤ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ í•˜ë‚˜ì”© êº¼ë‚´ì„œ í›ˆë ¨í•˜ëŠ” ê²ƒì´ ë” íš¨ìœ¨ì ì¼ë“¯ -> ì†ì‹¤í•¨ìˆ˜ë¥¼ ë¡œì§€ìŠ¤í‹±ìœ¼ë¡œ í•œ sgdì“°ì\n",
    "- SGDClassfierëŠ” í‘œì¤€í™” ì „ì²˜ë¦¬ê°€ í•„ìš”í–ˆì—ˆìŒ -> ê·¼ë° ì–´ì°¨í”¼ ê° í”½ì…€ë“¤ì´ 0~255 ì‚¬ì´ì˜ ì •ìˆ˜ë‹ˆê¹Œ, ê·¸ëƒ¥ 255ë¡œ ë‚˜ëˆ ì„œ ì •ê·œí™”\n",
    "\n",
    "ëª¨ë¸ í›ˆë ¨\n",
    "- ê²½ì‚¬í•˜ê°•ë²•ì„ í™œìš©í•œ ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨ë¸ì„, cross_validateë¥¼ í›ˆë ¨&í‰ê°€í•¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sc = SGDClassifier(loss='log_loss', max_iter=5, random_state=42)\n",
    "\n",
    "scores = cross_validate(sc, train_scaled, train_target, n_jobs=-1)\n",
    "print(np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¸ê³µì‹ ê²½ë§ì—ì„œëŠ” ë°ì´í„° ì¶©ë¶„í•´ì„œ êµì°¨ê²€ì¦ êµ³ì´ ì•ˆ í•¨\n",
    "from sklearn.model_selection import train_test_split # ê·¸ë˜ì„œ ê²€ì¦ ì„¸íŠ¸ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ëœì–´ë‚´ì„œ ì‚¬ìš©í•˜ê² ìŒ\n",
    "\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_scaled.shape, train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_scaled.shape, val_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¸ê³µì‹ ê²½ë§ì˜ ì¶œë ¥ì¸µì„ ë§Œë“¤ì–´ë³´ì\n",
    "# ê°€ì¥ ê¸°ë³¸ì¸ 'ë°€ì§‘ì¸µ dense'ë¡œ\n",
    "dense = keras.layers.Dense(10, activation='softmax', input_shape=(784,))\n",
    "#ìœ ë‹› 10ê°œ/ì¶œë ¥ì— ì ìš©í•  í•¨ìˆ˜ëŠ” ì†Œí”„íŠ¸ë§¥ìŠ¤/ì…ë ¥ì€ 784ê°œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy') # ì§€ê¸ˆê¹Œì§€ ì¼ë˜ ì‚¬ì´í‚·ëŸ°ê³¼ ë‹¬ë¦¬, ì¼€ë¼ìŠ¤ ëª¨ë¸ì€ í›ˆë ¨í•˜ê¸° ì „ì— ì„¤ì • ë‹¨ê³„ê°€ ë”°ë¡œ ìˆìŒ.\n",
    "#â¡ï¸ .compile() ì—ì„œ ì†ì‹¤í•¨ìˆ˜, ì¸¡ì •ê°’ ë“±ì„ ì„¤ì •í•˜ë©´ ë¨!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss : ì†ì‹¤í•¨ìˆ˜ì˜ ì¢…ë¥˜ (ì´ê±°ëŠ” í•„ìˆ˜!!!!â­)\n",
    "- ì´ì§„ë¶„ë¥˜ëŠ” loss='binary_crossentropy' ; ì´ì§„ í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼\n",
    "- ë‹¤ì¤‘ë¶„ë¥˜ëŠ” loss='categorical_crossentropy' ; í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼\n",
    "- ê·¼ë°, sparse_categorical_crossentropyâ“\n",
    "ì›ë˜ ë‹¤ì¤‘ë¶„ë¥˜ì—ì„œ í¬ë¡œìŠ¤ì—”íŠ¸ë¡œí”¼ ì†ì‹¤í•¨ìˆ˜ë¥¼ ì“°ë ¤ë©´ íƒ€ê¹ƒê°’ì— 'ì›-í•« ì¸ì½”ë”©' ì²˜ë¦¬ë¥¼ í•´ì¤˜ì•¼ í•¨(â•í”ŒëŸ¬ìŠ¤ì•ŒíŒŒ ì°¸ì¡°). ê·¼ë°, ê·¸ê±¸ ì•ˆ í•˜ê³  ê·¸ëƒ¥ ì •ìˆ˜ë¡œ ëœ íƒ€ê¹ƒê°’ì„ ê·¸ëƒ¥ ì‚¬ìš©í•  ê²½ìš°ì— ì´ ì†ì‹¤í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•¨.\n",
    "metrics : ê¸°ë³¸ì ìœ¼ë¡œ ì¶œë ¥ë˜ëŠ” 'ì†ì‹¤ ê°’' ì´ì™¸ì— ì¶”ê°€ë¡œ ì¸¡ì •í•˜ê³  ì‹¶ì€ ê°’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_target[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_scaled, val_target) #ì¼€ë¼ìŠ¤ì—ì„œëŠ” .evaluate() ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€í•¨. (ğŸ†š ì‚¬ì´í‚·ëŸ°ì€ .score() ì˜€ìŒ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API ë°©ì‹ ë¹„êµ\n",
    "\n",
    "ì‚¬ì´í‚·ëŸ° vs ì¼€ë¼ìŠ¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ì‚¬ì´í‚·ëŸ° ëª¨ë¸\n",
    "- ëª¨ë¸ ê°ì²´ë¥¼ ë§Œë“¤ë©´ì„œ ì™ ë§Œí•œ ë§¤ê°œë³€ìˆ˜ ë‹¤ ì§€ì •í•¨ -> fitë¡œ í›ˆë ¨ -> scoreë¡œ í‰ê°€\n",
    "\n",
    "2. ì¼€ë¼ìŠ¤ ëª¨ë¸\n",
    "- ì‚¬ì´í‚·ëŸ°ë³´ë‹¤ ëª¨ë¸ ë§Œë“œëŠ” ê³¼ì •ì´ ë” ì„¸ë¶„í™”ëœ ëŠë‚Œ(í›ˆë ¨, í‰ê°€ ê³¼ì •ì€ ë¹„ìŠ·)\n",
    "- ì¸µ ê°ì²´ë¥¼ ë”°ë¡œ ë§Œë“¤ê³  -> ê·¸ê±¸ ëª¨ë¸ì— Sequentialë¡œ ì¶”ê°€í•˜ê³  -> ê·¸ ëª¨ë¸ì˜ ì„¤ì •ë„ compileë¡œ ë”°ë¡œ í•´ì¤Œ -> fitìœ¼ë¡œ í›ˆë ¨í•˜ëŠ” ê±´ ë˜‘ê°™ê³  -> í‰ê°€ëŠ” evaluateë¡œ í•¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
