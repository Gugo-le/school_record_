{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n",
      "263\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "data = \"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 2], [4, 2, 66], [4, 2, 66, 8], [4, 2, 66, 8, 67], [4, 2, 66, 8, 67, 68], [4, 2, 66, 8, 67, 68, 69], [4, 2, 66, 8, 67, 68, 69, 70]]\n"
     ]
    }
   ],
   "source": [
    "# 문장 토큰화, 예측 모델을 훈련하려면 한 단 계 더 나아가 문장을 여러 개의 작은 문장으로 나누는 작업을 수행해야 함.\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "print(input_sequences[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences,\n",
    "                           maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1] # 입력 시퀀스에서 레이블을 분리하는 코드\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words) # 레이블을 훈련에 사용할 수 있는 원-핫 인코딩으로 변환 -> to_categorical 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  4  2 66  8 67 68 69]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(xs[6])\n",
    "print(ys[6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 14:20:29.654718: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-08-12 14:20:29.654754: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-08-12 14:20:29.654761: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-08-12 14:20:29.655023: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-08-12 14:20:29.655040: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# 모델 만들기\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 8)) # 임베딩 층 :: 임베딩에서는 단어 하나당 벡터 하나가 필요. !!: 파라미터 개수는 전체 단어 수와 임베딩 차원 수의 곱이 됨.(단어 많지 않기에 8차원이면 충분)\n",
    "model.add(Bidirectional(LSTM(max_sequence_len-1))) # LSTM 층 :: 양방향 LSTM 층을 만들고 뉴런 개수는 시퀀스 최대 길이보다 1 작게 지정함.\n",
    "model.add(Dense(total_words, activation='softmax')) # 밀집 층 :: 전체 단어 개수의 뉴런을 가진 밀집 층임. 이 층의 각 뉴런은 입력값에 대해 다음 단어에 해당하는 모든 단어의 확률을 출력함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 14:20:30.480469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.0121 - loss: 5.5711\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.0487 - loss: 5.5621\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.0499 - loss: 5.5505\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.0419 - loss: 5.5268\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.0615 - loss: 5.4601\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.0525 - loss: 5.3366\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.0456 - loss: 5.2125\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.0499 - loss: 5.0926\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.0501 - loss: 5.0771\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.0406 - loss: 5.0750\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(xs, ys, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"in the town of athy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts_to_sequences 메서드를 사용해 토큰으로 바꾸어야 함.\n",
    "token_list = tokenizer.texts_to_sequences([seed_text])[0] # 하나의 값만 전달하지만 배열을 반환하기 때문에 반환하는 배열의 첫 번째 원소를 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음으로 훈련 데이터와 동일한 크기로 만들기 위해 패딩을 추가한다.\n",
    "token_list = pad_sequences([token_list],\n",
    "                           maxlen=max_sequence_len-1, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# 토큰 리스트의 다음 단어를 예측하기 위해 model.predict를 호출한다.\n",
    "predicted = np.argmax(model.predict(token_list), axis=-1) # model.predict()는 말뭉치에 있는 각 단어에 대한 확률을 반환한다. -> np.argmax 함수에 전달 -> 가장 큰 인덱스\n",
    "print(predicted) # 반환값: 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word[68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "sweet jeremy saw dublin and and and and and\n"
     ]
    }
   ],
   "source": [
    "# 예츨을 연결해 텍스트 생성하기\n",
    "seed_text = \"sweet jeremy saw dublin\"\n",
    "next_words=5\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list],  maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "    output_word = \"\"\n",
    "\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "횡설수설한 문장이 되어버렸다!!!???\n",
    "\n",
    "1. 훈련 텍스트가 정말 작아 사용할 문맥이 거의 없기 때문\n",
    "2. 시퀀스의 다음 단어 예측이 이전 단어에 의존하기 때문\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('./irish-lyrics-eof.txt').read()\n",
    "corpus = data.lower().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences,\n",
    "                           maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 8))\n",
    "model.add(Bidirectional(LSTM(max_sequence_len-1)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.0623 - loss: 7.2079\n",
      "Epoch 2/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 49ms/step - accuracy: 0.0657 - loss: 6.3803\n",
      "Epoch 3/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 51ms/step - accuracy: 0.0655 - loss: 6.3170\n",
      "Epoch 4/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - accuracy: 0.0678 - loss: 6.2861\n",
      "Epoch 5/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 46ms/step - accuracy: 0.0685 - loss: 6.1683\n",
      "Epoch 6/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 46ms/step - accuracy: 0.0631 - loss: 6.1426\n",
      "Epoch 7/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 49ms/step - accuracy: 0.0643 - loss: 6.1217\n",
      "Epoch 8/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 48ms/step - accuracy: 0.0675 - loss: 6.0631\n",
      "Epoch 9/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - accuracy: 0.0681 - loss: 6.0151\n",
      "Epoch 10/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 46ms/step - accuracy: 0.0695 - loss: 5.9626\n",
      "Epoch 11/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 46ms/step - accuracy: 0.0715 - loss: 5.8546\n",
      "Epoch 12/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 46ms/step - accuracy: 0.0791 - loss: 5.7958\n",
      "Epoch 13/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 46ms/step - accuracy: 0.0792 - loss: 5.7594\n",
      "Epoch 14/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - accuracy: 0.0804 - loss: 5.6822\n",
      "Epoch 15/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - accuracy: 0.0891 - loss: 5.6589\n",
      "Epoch 16/1000\n",
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - accuracy: 0.0861 - loss: 5.5950\n",
      "Epoch 17/1000\n",
      "\u001b[1m132/377\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - accuracy: 0.0846 - loss: 5.5554"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(xs, ys, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 향상할 수 있는 한 가지 방법은 여러 개의 LSTM 층을 쌓는 형식으로 구조를 변경하는 것.\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 8))\n",
    "model.add(Bidirectional(LSTM(max_sequence_len-1, return_sequences='True')))\n",
    "model.add(Bidirectional(LSTM(max_sequence_len-1)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(xs, ys, epochs=1000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
