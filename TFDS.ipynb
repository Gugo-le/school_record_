{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyO8ptUc3HWQgH3wsSYsp1K4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gugo-le/school_record_/blob/colab-%EC%8B%A4%EC%8A%B5/TFDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3sYVXllLGw6",
        "outputId": "2b1f3ad2-b6a2-4cfe-c4bc-c591b21d717e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "test\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "mnist_data = tfds.load(\"fashion_mnist\")\n",
        "for item in mnist_data:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = tfds.load(name=\"fashion_mnist\", split=\"train\")\n",
        "assert isinstance(mnist_train, tf.data.Dataset)\n",
        "print(type(mnist_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN8ZDbCuMsmt",
        "outputId": "7ea5f3a7-217b-4b58-d361-0435ce4ed43c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in mnist_train.take(1):\n",
        "    print(type(item))\n",
        "    print(item.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7BLSy71Mso2",
        "outputId": "a5021c61-9c62-475e-f511-3b88bf48735e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "dict_keys(['image', 'label'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in mnist_train.take(1):\n",
        "    print(type(item))\n",
        "    print(item.keys())\n",
        "    print(item['image'])\n",
        "    print(item['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW5W__hYMsrJ",
        "outputId": "70945464-dc5c-4316-b81d-483a61d12643"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "dict_keys(['image', 'label'])\n",
            "tf.Tensor(\n",
            "[[[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 18]\n",
            "  [ 77]\n",
            "  [227]\n",
            "  [227]\n",
            "  [208]\n",
            "  [210]\n",
            "  [225]\n",
            "  [216]\n",
            "  [ 85]\n",
            "  [ 32]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 61]\n",
            "  [100]\n",
            "  [ 97]\n",
            "  [ 80]\n",
            "  [ 57]\n",
            "  [117]\n",
            "  [227]\n",
            "  [238]\n",
            "  [115]\n",
            "  [ 49]\n",
            "  [ 78]\n",
            "  [106]\n",
            "  [108]\n",
            "  [ 71]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 81]\n",
            "  [105]\n",
            "  [ 80]\n",
            "  [ 69]\n",
            "  [ 72]\n",
            "  [ 64]\n",
            "  [ 44]\n",
            "  [ 21]\n",
            "  [ 13]\n",
            "  [ 44]\n",
            "  [ 69]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 80]\n",
            "  [114]\n",
            "  [ 80]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 26]\n",
            "  [ 92]\n",
            "  [ 69]\n",
            "  [ 68]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 71]\n",
            "  [ 74]\n",
            "  [ 83]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 78]\n",
            "  [ 74]\n",
            "  [ 74]\n",
            "  [ 83]\n",
            "  [ 77]\n",
            "  [108]\n",
            "  [ 34]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 55]\n",
            "  [ 92]\n",
            "  [ 69]\n",
            "  [ 74]\n",
            "  [ 74]\n",
            "  [ 71]\n",
            "  [ 71]\n",
            "  [ 77]\n",
            "  [ 69]\n",
            "  [ 66]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 77]\n",
            "  [ 80]\n",
            "  [ 80]\n",
            "  [ 78]\n",
            "  [ 94]\n",
            "  [ 63]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 63]\n",
            "  [ 95]\n",
            "  [ 66]\n",
            "  [ 68]\n",
            "  [ 72]\n",
            "  [ 72]\n",
            "  [ 69]\n",
            "  [ 72]\n",
            "  [ 74]\n",
            "  [ 74]\n",
            "  [ 74]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 80]\n",
            "  [ 77]\n",
            "  [106]\n",
            "  [ 61]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 80]\n",
            "  [108]\n",
            "  [ 71]\n",
            "  [ 69]\n",
            "  [ 72]\n",
            "  [ 71]\n",
            "  [ 69]\n",
            "  [ 72]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 72]\n",
            "  [ 72]\n",
            "  [ 75]\n",
            "  [ 78]\n",
            "  [ 72]\n",
            "  [ 85]\n",
            "  [128]\n",
            "  [ 64]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 88]\n",
            "  [120]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 72]\n",
            "  [ 77]\n",
            "  [ 74]\n",
            "  [ 74]\n",
            "  [ 77]\n",
            "  [ 78]\n",
            "  [ 83]\n",
            "  [ 83]\n",
            "  [ 66]\n",
            "  [111]\n",
            "  [123]\n",
            "  [ 78]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 85]\n",
            "  [134]\n",
            "  [ 74]\n",
            "  [ 85]\n",
            "  [ 69]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 81]\n",
            "  [ 75]\n",
            "  [ 61]\n",
            "  [151]\n",
            "  [115]\n",
            "  [ 91]\n",
            "  [ 12]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 10]\n",
            "  [ 85]\n",
            "  [153]\n",
            "  [ 83]\n",
            "  [ 80]\n",
            "  [ 68]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 80]\n",
            "  [ 68]\n",
            "  [ 61]\n",
            "  [162]\n",
            "  [122]\n",
            "  [ 78]\n",
            "  [  6]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 30]\n",
            "  [ 75]\n",
            "  [154]\n",
            "  [ 85]\n",
            "  [ 80]\n",
            "  [ 71]\n",
            "  [ 80]\n",
            "  [ 72]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 78]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 49]\n",
            "  [191]\n",
            "  [132]\n",
            "  [ 72]\n",
            "  [ 15]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 58]\n",
            "  [ 66]\n",
            "  [174]\n",
            "  [115]\n",
            "  [ 66]\n",
            "  [ 77]\n",
            "  [ 80]\n",
            "  [ 72]\n",
            "  [ 78]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 78]\n",
            "  [ 78]\n",
            "  [ 77]\n",
            "  [ 66]\n",
            "  [ 49]\n",
            "  [222]\n",
            "  [131]\n",
            "  [ 77]\n",
            "  [ 37]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 69]\n",
            "  [ 55]\n",
            "  [179]\n",
            "  [139]\n",
            "  [ 55]\n",
            "  [ 92]\n",
            "  [ 74]\n",
            "  [ 74]\n",
            "  [ 78]\n",
            "  [ 74]\n",
            "  [ 78]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 80]\n",
            "  [ 64]\n",
            "  [ 55]\n",
            "  [242]\n",
            "  [111]\n",
            "  [ 95]\n",
            "  [ 44]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 74]\n",
            "  [ 57]\n",
            "  [159]\n",
            "  [180]\n",
            "  [ 55]\n",
            "  [ 92]\n",
            "  [ 64]\n",
            "  [ 72]\n",
            "  [ 74]\n",
            "  [ 74]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 78]\n",
            "  [ 55]\n",
            "  [ 66]\n",
            "  [255]\n",
            "  [ 97]\n",
            "  [108]\n",
            "  [ 49]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 74]\n",
            "  [ 66]\n",
            "  [145]\n",
            "  [153]\n",
            "  [ 72]\n",
            "  [ 83]\n",
            "  [ 58]\n",
            "  [ 78]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 72]\n",
            "  [ 80]\n",
            "  [ 30]\n",
            "  [132]\n",
            "  [255]\n",
            "  [ 37]\n",
            "  [122]\n",
            "  [ 60]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 80]\n",
            "  [ 69]\n",
            "  [142]\n",
            "  [180]\n",
            "  [142]\n",
            "  [ 57]\n",
            "  [ 64]\n",
            "  [ 78]\n",
            "  [ 74]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 72]\n",
            "  [ 85]\n",
            "  [ 21]\n",
            "  [185]\n",
            "  [227]\n",
            "  [ 37]\n",
            "  [143]\n",
            "  [ 63]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 83]\n",
            "  [ 71]\n",
            "  [136]\n",
            "  [194]\n",
            "  [126]\n",
            "  [ 46]\n",
            "  [ 69]\n",
            "  [ 75]\n",
            "  [ 72]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 78]\n",
            "  [ 38]\n",
            "  [139]\n",
            "  [185]\n",
            "  [ 60]\n",
            "  [151]\n",
            "  [ 58]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  4]\n",
            "  [ 81]\n",
            "  [ 74]\n",
            "  [145]\n",
            "  [177]\n",
            "  [ 78]\n",
            "  [ 49]\n",
            "  [ 74]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 72]\n",
            "  [ 63]\n",
            "  [ 80]\n",
            "  [156]\n",
            "  [117]\n",
            "  [153]\n",
            "  [ 55]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 10]\n",
            "  [ 80]\n",
            "  [ 72]\n",
            "  [157]\n",
            "  [163]\n",
            "  [ 61]\n",
            "  [ 55]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 71]\n",
            "  [ 60]\n",
            "  [ 98]\n",
            "  [156]\n",
            "  [132]\n",
            "  [ 58]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 13]\n",
            "  [ 77]\n",
            "  [ 74]\n",
            "  [157]\n",
            "  [143]\n",
            "  [ 43]\n",
            "  [ 61]\n",
            "  [ 72]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 77]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 71]\n",
            "  [ 58]\n",
            "  [ 80]\n",
            "  [157]\n",
            "  [120]\n",
            "  [ 66]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 18]\n",
            "  [ 81]\n",
            "  [ 74]\n",
            "  [156]\n",
            "  [114]\n",
            "  [ 35]\n",
            "  [ 72]\n",
            "  [ 71]\n",
            "  [ 75]\n",
            "  [ 78]\n",
            "  [ 72]\n",
            "  [ 66]\n",
            "  [ 80]\n",
            "  [ 78]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 64]\n",
            "  [ 63]\n",
            "  [165]\n",
            "  [119]\n",
            "  [ 68]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 23]\n",
            "  [ 85]\n",
            "  [ 81]\n",
            "  [177]\n",
            "  [ 57]\n",
            "  [ 52]\n",
            "  [ 77]\n",
            "  [ 71]\n",
            "  [ 78]\n",
            "  [ 80]\n",
            "  [ 72]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 77]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 64]\n",
            "  [ 37]\n",
            "  [173]\n",
            "  [ 95]\n",
            "  [ 72]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 26]\n",
            "  [ 81]\n",
            "  [ 86]\n",
            "  [160]\n",
            "  [ 20]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 77]\n",
            "  [ 80]\n",
            "  [ 78]\n",
            "  [ 80]\n",
            "  [ 89]\n",
            "  [ 78]\n",
            "  [ 81]\n",
            "  [ 83]\n",
            "  [ 80]\n",
            "  [ 74]\n",
            "  [ 20]\n",
            "  [177]\n",
            "  [ 77]\n",
            "  [ 74]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 49]\n",
            "  [ 77]\n",
            "  [ 91]\n",
            "  [200]\n",
            "  [  0]\n",
            "  [ 83]\n",
            "  [ 95]\n",
            "  [ 86]\n",
            "  [ 88]\n",
            "  [ 88]\n",
            "  [ 89]\n",
            "  [ 88]\n",
            "  [ 89]\n",
            "  [ 88]\n",
            "  [ 83]\n",
            "  [ 89]\n",
            "  [ 86]\n",
            "  [  0]\n",
            "  [191]\n",
            "  [ 78]\n",
            "  [ 80]\n",
            "  [ 24]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 54]\n",
            "  [ 71]\n",
            "  [108]\n",
            "  [165]\n",
            "  [  0]\n",
            "  [ 24]\n",
            "  [ 57]\n",
            "  [ 52]\n",
            "  [ 57]\n",
            "  [ 60]\n",
            "  [ 60]\n",
            "  [ 60]\n",
            "  [ 63]\n",
            "  [ 63]\n",
            "  [ 77]\n",
            "  [ 89]\n",
            "  [ 52]\n",
            "  [  0]\n",
            "  [211]\n",
            "  [ 97]\n",
            "  [ 77]\n",
            "  [ 61]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 68]\n",
            "  [ 91]\n",
            "  [117]\n",
            "  [137]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 18]\n",
            "  [216]\n",
            "  [ 94]\n",
            "  [ 97]\n",
            "  [ 57]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 54]\n",
            "  [115]\n",
            "  [105]\n",
            "  [185]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  1]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [153]\n",
            "  [ 78]\n",
            "  [106]\n",
            "  [ 37]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 18]\n",
            "  [ 61]\n",
            "  [ 41]\n",
            "  [103]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [106]\n",
            "  [ 47]\n",
            "  [ 69]\n",
            "  [ 23]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]], shape=(28, 28, 1), dtype=uint8)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_test, info = tfds.load(name=\"fashion_mnist\", with_info=\"true\")\n",
        "print(info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr4GtXqYMstW",
        "outputId": "f3ab22c3-0a70-4961-960d-264a572dcc42"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='fashion_mnist',\n",
            "    full_name='fashion_mnist/3.0.1',\n",
            "    description=\"\"\"\n",
            "    Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
            "    \"\"\",\n",
            "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
            "    data_dir='/root/tensorflow_datasets/fashion_mnist/3.0.1',\n",
            "    file_format=tfrecord,\n",
            "    download_size=29.45 MiB,\n",
            "    dataset_size=36.42 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
            "    }),\n",
            "    supervised_keys=('image', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
            "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
            "    },\n",
            "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
            "      author    = {Han Xiao and\n",
            "                   Kashif Rasul and\n",
            "                   Roland Vollgraf},\n",
            "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
            "                   Algorithms},\n",
            "      journal   = {CoRR},\n",
            "      volume    = {abs/1708.07747},\n",
            "      year      = {2017},\n",
            "      url       = {http://arxiv.org/abs/1708.07747},\n",
            "      archivePrefix = {arXiv},\n",
            "      eprint    = {1708.07747},\n",
            "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
            "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
            "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
            "    }\"\"\",\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = \\\n",
        "    mnist.load_data()"
      ],
      "metadata": {
        "id": "YJV3YgL4NzSm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = \\\n",
        "    tfds.as_numpy(tfds.load('fashion_mnist',\n",
        "                            split = ['train', 'test'],\n",
        "                            batch_size=-1, # 모든 데이터 가져옴\n",
        "                            as_supervised=True)) #(입력, 레이블)로 구성된 투플이 반환된다."
      ],
      "metadata": {
        "id": "Kufqlk6oNzU1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = \\\n",
        "    tfds.load('fashion_mnist',\n",
        "              split = ['train', 'test'],\n",
        "              batch_size=-1,\n",
        "              as_supervised=True)\n",
        "\n",
        "training_images = tf.cast(training_images, tf.float32) / 255.0\n",
        "test_images = tf.cast(test_images, tf.float32) / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKnszrOAMsvW",
        "outputId": "e9916948-b123-42fe-a131-1942c2051430"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7611 - loss: 0.6726\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8543 - loss: 0.4048\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8645 - loss: 0.3673\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8726 - loss: 0.3462\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8808 - loss: 0.3250\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c16f4059a50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = tfds.load('horses_or_humans', split='train', as_supervised=True)\n",
        "\n",
        "train_batches = data.shuffle(100).batch(10)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu',\n",
        "                           input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='Adam', loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_batches, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ffTCrdMOz9I",
        "outputId": "93503b9d-123f-4632-f2b8-f5f2bec28727"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 990ms/step - accuracy: 0.6920 - loss: 3.5723\n",
            "Epoch 2/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 904ms/step - accuracy: 0.9518 - loss: 0.1660\n",
            "Epoch 3/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 890ms/step - accuracy: 0.9162 - loss: 0.1987\n",
            "Epoch 4/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 913ms/step - accuracy: 0.9871 - loss: 0.0407\n",
            "Epoch 5/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 903ms/step - accuracy: 0.9875 - loss: 0.0234\n",
            "Epoch 6/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 900ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 7/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 921ms/step - accuracy: 1.0000 - loss: 3.5357e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 928ms/step - accuracy: 1.0000 - loss: 1.2176e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 910ms/step - accuracy: 1.0000 - loss: 8.9552e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 901ms/step - accuracy: 1.0000 - loss: 6.1933e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c16ede83be0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = tfds.load('horses_or_humans', split='test', as_supervised=True)"
      ],
      "metadata": {
        "id": "kFv8a48POz-N"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_batches = val_data.batch(32)"
      ],
      "metadata": {
        "id": "lCR8xuDrO0Aw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_batches, epochs=10,\n",
        "          validation_data=validation_batches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjfqCybTO0C2",
        "outputId": "4ead5d48-c3d3-4004-cad5-bd993187d0a3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 992ms/step - accuracy: 1.0000 - loss: 4.9098e-05 - val_accuracy: 0.8672 - val_loss: 2.9224\n",
            "Epoch 2/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 984ms/step - accuracy: 1.0000 - loss: 3.0692e-05 - val_accuracy: 0.8672 - val_loss: 3.0007\n",
            "Epoch 3/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 971ms/step - accuracy: 1.0000 - loss: 3.1893e-05 - val_accuracy: 0.8672 - val_loss: 3.0658\n",
            "Epoch 4/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 975ms/step - accuracy: 1.0000 - loss: 2.6731e-05 - val_accuracy: 0.8672 - val_loss: 3.1667\n",
            "Epoch 5/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 973ms/step - accuracy: 1.0000 - loss: 1.9229e-05 - val_accuracy: 0.8672 - val_loss: 3.1907\n",
            "Epoch 6/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 972ms/step - accuracy: 1.0000 - loss: 1.6814e-05 - val_accuracy: 0.8672 - val_loss: 3.2783\n",
            "Epoch 7/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 971ms/step - accuracy: 1.0000 - loss: 1.2930e-05 - val_accuracy: 0.8672 - val_loss: 3.3296\n",
            "Epoch 8/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 976ms/step - accuracy: 1.0000 - loss: 1.3532e-05 - val_accuracy: 0.8711 - val_loss: 3.3572\n",
            "Epoch 9/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 989ms/step - accuracy: 1.0000 - loss: 1.1661e-05 - val_accuracy: 0.8711 - val_loss: 3.4004\n",
            "Epoch 10/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 984ms/step - accuracy: 1.0000 - loss: 8.4613e-06 - val_accuracy: 0.8711 - val_loss: 3.4590\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c16e5e92170>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 특정 버전의 데이터셋 로드하기"
      ],
      "metadata": {
        "id": "BWjyUzY7QX3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data, info = tfds.load(\"horses_or_humans:3.0.0\", with_info=True)"
      ],
      "metadata": {
        "id": "rxn-sooRQbm5"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}